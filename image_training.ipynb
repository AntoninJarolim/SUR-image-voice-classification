{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUR image model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.utils.data\n",
    "import torchvision.datasets\n",
    "from torchvision.transforms import v2\n",
    "import torchvision.transforms.functional\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convolutional neural network for binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Eye(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, 3, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        #40x40\n",
    "        self.conv2a = nn.Conv2d(16, 16, 3, padding=1)\n",
    "        self.conv2b = nn.Conv2d(16, 32, 3, padding=1)\n",
    "        self.batchNorm2 = nn.BatchNorm2d(32)\n",
    "        #20x20\n",
    "        self.conv3a = nn.Conv2d(32, 32, 3, padding=1)\n",
    "        self.conv3b = nn.Conv2d(32, 64, 3, padding=1)\n",
    "        self.batchNorm3 = nn.BatchNorm2d(64)\n",
    "        #10x10\n",
    "\n",
    "        self.conv4a = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.conv4b = nn.Conv2d(64, 64, 3, padding=1)\n",
    "        self.batchNorm4 = nn.BatchNorm2d(64)\n",
    "        # 5x5\n",
    "\n",
    "        self.lin1 = nn.Linear(5*5*64, 64)\n",
    "        self.lin2 = nn.Linear(64, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.pool1(x)\n",
    "        #40x40\n",
    "        x = self.conv2a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.batchNorm2(x)\n",
    "        x = self.pool1(x)\n",
    "        #20x20\n",
    "        x = self.conv3a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv3b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.batchNorm3(x)\n",
    "        x = self.pool1(x)\n",
    "        #10x10\n",
    "        x = self.conv4a(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv4b(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.batchNorm4(x)\n",
    "        x = self.pool1(x)\n",
    "        #5x5x128\n",
    "\n",
    "        x = torch.flatten(x, 1)\n",
    "\n",
    "        x = self.lin1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.lin2(x)\n",
    "        x = torch.sigmoid(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper transform for data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data\n",
    "to_torch = v2.Compose([\n",
    "    v2.ToImage(),\n",
    "    v2.ToDtype(torch.float32, scale=True)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Used augmentations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddGaussianNoise(object):\n",
    "    def __init__(self, mean=0., std=1.):\n",
    "        self.std = std\n",
    "        self.mean = mean\n",
    "        \n",
    "    def __call__(self, tensor):\n",
    "        return torch.clamp(tensor + torch.randn(tensor.size(), dtype=torch.float) * self.std + self.mean, 0, 1)\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return self.__class__.__name__ + '(mean={0}, std={1})'.format(self.mean, self.std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Augmentation\n",
    "transforms = v2.Compose([\n",
    "    v2.RandomHorizontalFlip(),\n",
    "    v2.RandomAffine(15, [0.05,0.05], [0.9,1.1]),\n",
    "    v2.GaussianBlur(3),\n",
    "    v2.RandomApply([AddGaussianNoise(0, 0.15)], p=0.3),\n",
    "    v2.RandomPhotometricDistort()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data loading."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_train = torchvision.datasets.ImageFolder(\"data/training\", transform=to_torch)\n",
    "target_validation = torchvision.datasets.ImageFolder(\"data/validation\", transform=to_torch)\n",
    "\n",
    "inverse_counts = 1 / np.bincount([x[1] for x in target_train])\n",
    "class_weights = [inverse_counts[x[1]] for x in target_train]\n",
    "\n",
    "# Target class oversampling\n",
    "sampler = torch.utils.data.WeightedRandomSampler(class_weights, len(target_train), replacement=True)\n",
    "\n",
    "loader = torch.utils.data.DataLoader(target_train, batch_size=30, sampler=sampler)\n",
    "validation_loader = torch.utils.data.DataLoader(target_validation, batch_size=len(target_validation))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Augmentation example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = target_train[0][0]\n",
    "display(torchvision.transforms.functional.to_pil_image(transforms(x)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Eye()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-2)\n",
    "lfunc = torch.nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    for batch in iter(loader):\n",
    "        inputs, labels = batch\n",
    "        inputs = transforms(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        result = model(inputs)\n",
    "        loss:torch.Tensor = lfunc(result, labels.reshape([len(labels),1]).float())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in validation_loader:\n",
    "            inputs, labels = batch\n",
    "            result = model(inputs)\n",
    "            loss:torch.Tensor = lfunc(result, labels.reshape([len(labels),1]).float())\n",
    "            print(i, loss.item())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model export."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"image_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
